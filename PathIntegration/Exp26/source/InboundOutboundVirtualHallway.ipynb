{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inbound/outbound hallway with 360 loops\n",
    "\n",
    "Next is a summary of the new version of the inbound/outbound hallway. This correspond to experiment number 26, and the files for it will be inside Exp26 folder of the 'PathIntegration' experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for the previous version of the hallway, I am using the codes inside the 'inbound_outbound_hallway' folder in the desktop of the computer in the behavior cave (which I will also add inside this folder)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the novelties in this version compared to previous versions is that we will be triggering a camera to measure proboscis extension. I am using the blackfly camera on the side of my fly to measure this, and I'm triggering it as defined in the corresponding notebook on Evernote. I'm currently acquiring at 10 Hz, but that might be tweaked moving forward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The additional change to this version of the hallway compared to the previous version is that we are adding a couple of 360 loops in some of the left trials: instances in which during the open-loop bout, the stimulus will rotate 360 deg instead of 180. The fly shouldn't expect to receive a reward in this case in the second part of these trips."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "In this experiment, the panels emulate a hallway in which the flies are walking from one end to the other, and receive a reward in the middle. This is generated by setting optic flow (low contrast grating) to be in closed-loop with the animal's forward velocity. Once the fly reaches 'the end' of the hallway, the loop is open, and the panels are rotated by 180 deg. This changes the fly from a 'left' trip to a 'right' trip or vice-versa. A visual cue to signal the fly what type of trip she's on is a bright blue bar that's static on either side of the hallway, and can be thought of as a celestial cue. The reward is virtual and given by shining a 0.5 sec 660 nm LED pulse on flies that express chrimson in sweet sensors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next is a schematic of what the experiment is looking to emulate:\n",
    "<img src=\"Z:/Wilson Lab/Mel/Experiments/PathIntegration/Exp26/source/hallway_schematic.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods\n",
    "\n",
    "For the first round of the experiment, we will be using the next set of genotypes:\n",
    "1. Experimental: w+;+;Gr43aLexA/LexAOpChr:tdT\n",
    "2. Parental controls: w+;+;Gr43aLexA and w+;+;LexAOpChr;tdT\n",
    "Both the experimental and control flies will be raised on homemade german food + ATR.\n",
    "\n",
    "24-48 h prior to the experiment, the flies will be starved in an empty vial containing a kimwipe wet with a mixture of 1 mL DI water + 1 mL 1 mM ATR solution.\n",
    "\n",
    "We will use 3-6 day old virgins. They will be collected on C02 the day they ecclose, and their wings will be clipped. They will then be transferred to a new vial with ATR food and allowed to recover for at least 1 day, until they are ready to be starved.\n",
    "\n",
    "The flies will be placed in a 4:4 light cycle, and will be used starting around 1 pm, to be near the peak of maximum activity.\n",
    "\n",
    "If the animals are not walking much, we will use the enclosure heater to encourage walking through heating (and use the humidifier to prevent the flies from dying in that case). If we resort to this, it will be indicated in the metadata.\n",
    "\n",
    "The movement from the flies will be reconstructed using FicTrac to track the ball at 50 Hz (through a USB3 Chamaleon camera). The side of the flies will be filmed with a Blackfly camera, whose acquisition will be triggered by Matlab through the NiDaq at 10 Hz. This data will later be used to track proboscis movement (and if possible, leg movement)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Protocol\n",
    "\n",
    "To run the experiment:\n",
    "1. Position the fly on the ball using all three cameras (Firefly, Blackfly and Chamaleon). The positioning of the fly is VERY important! This is key to determine how well she will walk, which when studying path integration is likely very important. Things to look for are: that her long axis is overall pretty parallel to the table when looking at her from the blackfly camera, that when looking at her from the back in the firefly camera, both of her sides look even (the stumps left from the wings are usually a good way to look at this), that her long axis is parallel to the side of the holder when looking at her in the chamaleon camera.\n",
    "2. Run the fictrac configuration (you can find this here C:\\Users\\Wilson\\Desktop\\src\\fictrac-master\\bin\\Release), start fictrac and make sure it's working correctly (the accumulated map is not resetting).\n",
    "3. Let her get used to the ball for 10 min in the darkness.\n",
    "4. Run the 'fly_experiments.m' code. You will be prompted to select the folder where the data will be saved: choose the 'data' folder, inside the 'Exp26' folder. You will then be asked for an experiment name, and you should provide the genotype name (note: this prompt can't interpret the sign '/' correctly, so I would write w+;+;Gr43aLexA,LexAOpChrtdT for this genotype).\n",
    "5. Once you have inputed the folder and name, a new folder will be created with the date and the flies genotype. Navigate to that folder and create a folder called 'proboscis', where we will store the images acquired with the Blackfly.\n",
    "6. Open the Blackfly configuration panel, and click the 'camera control dialog' button.\n",
    "<img src=\"Z:/Wilson Lab/Mel/Experiments/PathIntegration/Exp26/source/blackfly_with_settings.png\" width=\"400\">\n",
    "\n",
    "\n",
    "In the tab 'custom video modes', drag the mouse to create a smaller window around the fly, and apply to visualize the result.\n",
    "\n",
    "<img src=\"Z:/Wilson Lab/Mel/Experiments/PathIntegration/Exp26/source/blackfly_custom_video_modes.png\" width=\"500\">\n",
    "\n",
    "In the 'trigger/strobe' window, click 'Enable' under 'trigger control'. Then, in the main camera window, click the record button to 'capture video or image sequence'. In the pop up window, browse the folder to save the images inside the 'proboscis' folder you just generated. Choose to save '1000000' frames, such that we for sure won't run out of space. Select 'TIF' for the image format, and press on 'start recording' (this will wait for the trigger signal to start acquiring.\n",
    "\n",
    "<img src=\"Z:/Wilson Lab/Mel/Experiments/PathIntegration/Exp26/source/blackfly_recording.png\" width=\"500\">\n",
    "\n",
    "\n",
    "7. Go now to the GUI that the 'fly_experiments' code opened. Select '3600' as the trial length (this will be the max length before the experiment is terminated. Under 'Panel stimulus', choose 'closed_loop_x_closed_loop_y' as the mode (in our experiment, the y dimension of the panels will be in closed-loop with the animal's forward velocity; the x dimension of the panels is in reality not in closed-loop with the animals, but I'm setting it in this mode and then setting it to open loop in the python code, to allow for the 180 and 360 deg turns at specific moments. Write down 60 for the trips number, 39 for the pattern, and 50 for the reward distance: we're setting the reward in the middle of the hallway to have twice as many probe trials to analyze (both sides will be equivalent here).\n",
    "\n",
    "<img src=\"Z:/Wilson Lab/Mel/Experiments/PathIntegration/Exp26/source/fly_experiments_gui.png\" width=\"500\">\n",
    "\n",
    "8. Once the experiment ends, it will prompt you to input some information about the fly (age, starvation time, ...), which will be saved as metadata.\n",
    "9. Run the 'runOptoPulses.m' function, using the arguments 300,10,1, to signal you want the fly to receive 1 sec long LED pulses every 10 sec for 5 min."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "To analyze the data, we will be using a main Matlab code, called 'analysis' that lives in this folder, and some dependent utils that are called by it.\n",
    "For the proboscis extension data, we will be running DeepLabCut. The images first need to be transformed to video and this can be done using the python code called 'ImageCompression.ipynb'.\n",
    "This code, as well as all the hallway code, will live in the 'Exp26' folder, in the server and in github."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
